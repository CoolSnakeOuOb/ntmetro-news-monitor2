import streamlit as st
import collections
from serpapi import GoogleSearch
import streamlit.components.v1 as components
import requests # æ–°å¢ï¼Œç”¨æ–¼æŸ¥è©¢å¸³æˆ¶è³‡è¨Š

# --- Setup: API Key & Core Functions ---

SERPAPI_API_KEY = st.secrets.get("SERPAPI_API_KEY")

@st.cache_data(ttl=60) # ä½¿ç”¨å¿«å–ï¼Œæ¯ 1 åˆ†é˜(60ç§’)æ‰é‡æ–°æŠ“å–ä¸€æ¬¡
def get_serpapi_account_info(api_key):
    """å‘¼å« SerpApi çš„å¸³æˆ¶ APIï¼Œä¸¦å›å‚³å¸³æˆ¶è³‡è¨Šã€‚"""
    if not api_key:
        return None
    try:
        response = requests.get(f"https://serpapi.com/account?api_key={api_key}")
        response.raise_for_status()
        return response.json()
    except requests.RequestException:
        return None

def is_published_very_recently(date_str: str) -> bool:
    """æ¡ç”¨æ‚¨çš„æœ€çµ‚ç‰ˆé‚è¼¯ï¼šåªæ¥å—æ™‚é–“å–®ä½ç‚ºç§’ã€åˆ†é˜ã€å°æ™‚çš„æ–°èã€‚"""
    if not isinstance(date_str, str):
        return False
    date_str_lower = date_str.lower()
    return any(marker in date_str_lower for marker in ["second", "ç§’", "minute", "åˆ†é˜", "hour", "å°æ™‚"])

def fetch_news_from_light_api(keywords: list):
    """ç‚ºæ¯å€‹é—œéµå­—å‘¼å« google_news_light APIï¼Œç²å–å¤§é‡åŸå§‹çµæœä»¥ä¾›ç¯©é¸ã€‚"""
    raw_results = collections.defaultdict(list)
    if not SERPAPI_API_KEY:
        st.error("éŒ¯èª¤ï¼šè«‹åœ¨ .streamlit/secrets.toml ä¸­è¨­å®šæ‚¨çš„ SERPAPI_API_KEY")
        return raw_results
    for kw in keywords:
        params = {
            "engine": "google_news_light",
            "q": kw,
            "api_key": SERPAPI_API_KEY,
            "hl": "zh-tw",
            "gl": "tw",
            "num": 100,
            "tbs": "qdr:d"
        }
        try:
            search = GoogleSearch(params)
            data = search.get_dict()
            if "news_results" in data:
                raw_results[kw] = data["news_results"]
        except Exception as e:
            st.error(f"æœå°‹é—œéµå­— '{kw}' æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    return raw_results

# --- Streamlit UI ---

st.set_page_config(page_title="æ·é‹è¼¿æƒ…å·¥å…·", page_icon="ğŸš‡", layout="wide")
st.title("ğŸ“° æ–°åŒ—æ·é‹è¼¿æƒ…å·¥å…·")

# ã€æ–°å¢ã€‘åœ¨æ¨™é¡Œä¸‹æ–¹é¡¯ç¤º API é¡åº¦è³‡è¨Š
if SERPAPI_API_KEY:
    account_info = get_serpapi_account_info(SERPAPI_API_KEY)
    if account_info and 'plan_searches_left' in account_info:
        st.info(f"æœ¬æœˆå‰©é¤˜æœå°‹é¡åº¦ï¼š {account_info['plan_searches_left']} / {account_info['searches_per_month']}")
    else:
        st.warning("ç„¡æ³•ç²å– API é¡åº¦è³‡è¨Šï¼Œè«‹ç¢ºèªæ‚¨çš„ API é‡‘é‘°æ˜¯å¦æ­£ç¢ºã€‚")

with st.expander("ğŸ“– ä½¿ç”¨èªªæ˜"):
    st.markdown("""
    1.  **è¼¸å…¥é—œéµå­—**ï¼šç”¨é€—è™Ÿåˆ†éš”ã€‚
    2.  **æŠ“å–èˆ‡ç¯©é¸**ï¼šé»æ“ŠæŒ‰éˆ•å¾Œï¼Œç¨‹å¼æœƒæŠ“å–æœ€å¤š 100 å‰‡æ–°èï¼Œä¸¦ç¯©é¸å‡º24å°æ™‚å…§çš„æ–°èã€‚
    3.  **å‹¾é¸èˆ‡åˆ†é¡**ï¼šå¾ç¯©é¸å¾Œçš„çµæœä¸­æŒ‘é¸æ‚¨éœ€è¦çš„æ–‡ç« ã€‚
    4.  **ç”¢ç”Ÿå ±è¡¨**ï¼šç”¢ç”Ÿæœ€çµ‚çš„ LINE æ ¼å¼è¨Šæ¯ã€‚
    """)

if 'filtered_news' not in st.session_state:
    st.session_state.filtered_news = collections.defaultdict(list)

default_keywords = "æ·é‹, è¼•è»Œ, ç’°ç‹€ç·š, æ–°åŒ—, è»Œé“, éµè·¯"
keywords_input = st.text_input("ğŸ” è¼¸å…¥é—œéµå­—ï¼ˆé€—è™Ÿåˆ†éš”ï¼‰", default_keywords)

if st.button("ğŸ“¥ æŠ“å–ä¸¦ç¯©é¸è¿‘æœŸæ–°è"):
    keyword_list = [k.strip() for k in keywords_input.split(",") if k.strip()]
    if not keyword_list:
        st.warning("è«‹è¼¸å…¥æœ‰æ•ˆçš„é—œéµå­—ã€‚")
    elif not SERPAPI_API_KEY:
        st.error("è«‹å…ˆåœ¨ .streamlit/secrets.toml ä¸­è¨­å®šæ‚¨çš„ SERPAPI_API_KEYã€‚")
    else:
        with st.spinner("ğŸ”„ æ­£åœ¨æŠ“å–æœ€æ–°æ–°è..."):
            all_news_results = fetch_news_from_light_api(keyword_list)
        
        filtered_results = collections.defaultdict(list)
        with st.spinner("ğŸ” æ­£åœ¨é€²è¡Œæ™‚é–“ç¯©é¸..."):
            for kw, items in all_news_results.items():
                for item in items:
                    if is_published_very_recently(item.get("date")):
                        if item.get("title") and item.get("link"):
                           filtered_results[kw].append(item)
        
        st.session_state.filtered_news = filtered_results
        
        total_found = sum(len(v) for v in filtered_results.values())
        st.success(f"âœ… ç¯©é¸å®Œæˆï¼ç¸½å…±æ‰¾åˆ°äº† {total_found} å‰‡è¿‘æœŸæ–°èã€‚")

# --- å‹¾é¸èˆ‡åˆ†é¡è¡¨å–® ---
if st.session_state.filtered_news:
    st.header("Step 2: å‹¾é¸ä¸¦åˆ†é¡æ‚¨éœ€è¦çš„æ–°è")
    with st.form("news_selection_form"):
        selected_articles_data = []
        categories = ["ã€æ–°åŒ—ã€‘", "ã€åŒæ¥­ã€‘", "ã€å…¶ä»–ã€‘"]
        
        keyword_list_in_scope = [k.strip() for k in keywords_input.split(",") if k.strip()]

        for kw in keyword_list_in_scope:
            items = st.session_state.filtered_news.get(kw, [])
            if items:
                st.subheader(f"ğŸ”¸ {kw}")
                for i, article in enumerate(items):
                    title = article.get('title', "ç„¡æ¨™é¡Œ")
                    url = article.get('link', "#")
                    key = f"select_{kw}_{i}"

                    col1, col2 = st.columns([0.8, 0.2])
                    with col1:
                        is_selected = st.checkbox(f"[{title}]({url})", key=key, help=f"ä¾†æºï¼š{article.get('source', 'æœªçŸ¥')} - ç™¼å¸ƒæ–¼: {article.get('date', 'æœªçŸ¥')}")
                    with col2:
                        category = st.radio("åˆ†é¡", options=categories, key=f"cat_{kw}_{i}", horizontal=True, label_visibility="collapsed")
                    
                    if is_selected:
                        article['category'] = category
                        selected_articles_data.append(article)
        
        submitted = st.form_submit_button("âœ… ç”¢ç”Ÿ Line è¨Šæ¯")

        # --- å ±è¡¨ç”¢ç”Ÿ ---
        if submitted:
            st.header("Step 3: è¤‡è£½ä»¥ä¸‹è¨Šæ¯")
            if not selected_articles_data:
                st.warning("âš ï¸ è«‹è‡³å°‘å‹¾é¸ä¸€å‰‡æ–°è")
            else:
                grouped_news = collections.defaultdict(list)
                for item in selected_articles_data:
                    category = item.get('category', "ã€å…¶ä»–ã€‘")
                    grouped_news[category].append(item)
                
                result_msg = "å„ä½é•·å®˜ã€åŒä»æ—©å®‰ï¼Œ\nä»Šæ—¥æ–°èè¼¿æƒ…é€£çµå¦‚ä¸‹ï¼š\n\n"
                
                category_order = ["ã€æ–°åŒ—ã€‘", "ã€åŒæ¥­ã€‘", "ã€å…¶ä»–ã€‘"]
                for category in category_order:
                    if category in grouped_news:
                        result_msg += f"{category}\n"
                        for item in grouped_news[category]:
                            result_msg += f"{item['title']}\n{item['link']}\n\n"

                st.success("âœ… å·²ç”¢ç”Ÿå ±è¡¨")
                st.text_area("ğŸ“‹ LINE å ±è¡¨å…§å®¹ (å¯è¤‡è£½)", result_msg.strip(), height=400)
                js_safe_msg = result_msg.strip().replace('`','\\`').replace('\\','\\\\').replace('$', '\\$')
                components.html(f"""
                    <button onclick="copyText()" style="font-size:16px;padding:8px 16px;margin-top:10px; border-radius: 5px; border: 1px solid #ccc; cursor: pointer;">
                        ğŸ“‹ è¤‡è£½åˆ°å‰ªè²¼ç°¿
                    </button>
                    <script>
                    function copyText() {{
                        const text = `{js_safe_msg}`;
                        navigator.clipboard.writeText(text).then(function() {{
                            alert("âœ… å·²è¤‡è£½ï¼");
                        }}, function(err) {{
                            alert("âŒ å¤±æ•—ï¼š" + err);
                        }});
                    }}
                    </script>
                """, height=70)